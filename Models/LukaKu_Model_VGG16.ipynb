{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LukaKu_Model_VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6N_RMy-0zeK",
        "outputId": "fbfc8c04-175d-468b-dbb9-e969ed05d9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun 12 09:06:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR82xqVT02KP",
        "outputId": "f4089856-7456-4790-9fcf-a854e46054f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/LukaKu/Dataset/Dataset_capstone_final.zip'"
      ],
      "metadata": {
        "id": "5x_k4mlJ03vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7ge4O-h09s1",
        "outputId": "aa9aff39-e272-43d0-cee5-3d032862b611"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "dir_i = os.listdir('/content/Dataset_img_final')\n",
        "\n",
        "for i in dir_i:\n",
        "  dir_a = os.path.join('/content/Dataset_img_final', i)\n",
        "  print(i, ' has ', len(os.listdir(dir_a)), ' images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-slmpB_1BLF",
        "outputId": "1a359ab0-4ceb-4cc9-b99c-af1d82c6f780"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orthopaedic wounds  has  49  images\n",
            "miscellaneous  has  56  images\n",
            "leg-ulcer-images  has  134  images\n",
            "foot-ulcers  has  384  images\n",
            "pressure ulcer  has  856  images\n",
            "epidermolysis-bullosa  has  5  images\n",
            "toes  has  35  images\n",
            "haemangioma  has  6  images\n",
            "DFU  has  673  images\n",
            "burns  has  457  images\n",
            "malignant-wound-images  has  9  images\n",
            "meningitis  has  24  images\n",
            "normal  has  300  images\n",
            "venous  has  411  images\n",
            "extravasation-wound-images  has  20  images\n",
            "pilonidal-sinus  has  3  images\n",
            "surgical  has  420  images\n",
            "skin tears  has  54  images\n",
            "abdominal-wounds  has  13  images\n",
            "trauma  has  93  images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/Dataset_img_final/pilonidal-sinus\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/haemangioma\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/epidermolysis-bullosa\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/extravasation-wound-images\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/malignant-wound-images\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/abdominal-wounds\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/meningitis\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/toes\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/miscellaneous\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/skin tears\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/trauma\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/orthopaedic wounds\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/leg-ulcer-images\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/normal\" \"/content/content\"\n",
        "!mv \"/content/Dataset_img_final/DFU\" \"/content/content\""
      ],
      "metadata": {
        "id": "g-7uFRfS1Kin"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "\n",
        "folder = '/content/Dataset_img_final'\n",
        "\n",
        "splitfolders.ratio(folder, output='/content/Dataset_split',\n",
        "                 seed=42, ratio=(0.8, 0.2),\n",
        "                 group_prefix = None\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R67UGLM_ClA",
        "outputId": "f5c287bd-0266-49f6-e701-88ebefe147e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2528 files [00:00, 2820.75 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "dir_i = os.listdir('/content/Dataset_split/train')\n",
        "\n",
        "for i in dir_i:\n",
        "  dir_a = os.path.join('/content/Dataset_split/train', i)\n",
        "  print(i, ' has ', len(os.listdir(dir_a)), ' images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ovCPhTn_e-t",
        "outputId": "737256fe-c0cf-4995-ab30-69f6762d84f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "foot-ulcers  has  307  images\n",
            "pressure ulcer  has  684  images\n",
            "burns  has  365  images\n",
            "venous  has  328  images\n",
            "surgical  has  336  images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "dir_i = os.listdir('/content/Dataset_split/val')\n",
        "\n",
        "for i in dir_i:\n",
        "  dir_a = os.path.join('/content/Dataset_split/val', i)\n",
        "  print(i, ' has ', len(os.listdir(dir_a)), ' images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA1oCgX3ACH-",
        "outputId": "c1469346-4e1b-4071-a5ed-13d06c0890ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "foot-ulcers  has  77  images\n",
            "pressure ulcer  has  172  images\n",
            "burns  has  92  images\n",
            "venous  has  83  images\n",
            "surgical  has  84  images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "pre_trained_model = VGG16(input_shape=(150,150,3),\n",
        "                                    include_top=False,\n",
        "                                    weights='imagenet')\n",
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyL_4iYhAUmY",
        "outputId": "b519f7b7-fe37-4eac-d416-032c9da28d9c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/Dataset_split/train'\n",
        "val_dir = '/content/Dataset_split/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('block4_pool')\n",
        "last_output = last_layer.output\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    ) # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    val_dir, # same directory as training data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    )\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=20, restore_best_weights=True)\n",
        "model_2 = Model(pre_trained_model.input, x)\n",
        "model_2.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZSc1fGjA55w",
        "outputId": "c0ea6033-9efb-4486-f820-10fe9f8e2c8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2020 images belonging to 5 classes.\n",
            "Found 508 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "mc = ModelCheckpoint('best_model_VGG16.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "NbtjbjE8BNK3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_2.fit(train_generator,\n",
        "            steps_per_epoch= 2020/32,\n",
        "            validation_steps= 508/32,\n",
        "            epochs=100,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=1,\n",
        "            callbacks=[callbacks,mc]\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiSjKQsLB4Ds",
        "outputId": "727b6185-fc88-4b7e-8f6a-05b7ae44df0c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 18.0645 - acc: 0.4099\n",
            "Epoch 1: val_acc improved from -inf to 0.55709, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 43s 490ms/step - loss: 18.0645 - acc: 0.4099 - val_loss: 1.1701 - val_acc: 0.5571\n",
            "Epoch 2/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 1.2791 - acc: 0.5010\n",
            "Epoch 2: val_acc improved from 0.55709 to 0.57283, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 451ms/step - loss: 1.2791 - acc: 0.5010 - val_loss: 1.1579 - val_acc: 0.5728\n",
            "Epoch 3/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 1.1846 - acc: 0.5594\n",
            "Epoch 3: val_acc improved from 0.57283 to 0.63976, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 451ms/step - loss: 1.1846 - acc: 0.5594 - val_loss: 0.9741 - val_acc: 0.6398\n",
            "Epoch 4/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 1.1218 - acc: 0.5807\n",
            "Epoch 4: val_acc improved from 0.63976 to 0.67520, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 450ms/step - loss: 1.1218 - acc: 0.5807 - val_loss: 0.9311 - val_acc: 0.6752\n",
            "Epoch 5/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 1.0639 - acc: 0.6000\n",
            "Epoch 5: val_acc did not improve from 0.67520\n",
            "63/63 [==============================] - 27s 423ms/step - loss: 1.0639 - acc: 0.6000 - val_loss: 0.9299 - val_acc: 0.6614\n",
            "Epoch 6/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 1.0402 - acc: 0.6218\n",
            "Epoch 6: val_acc did not improve from 0.67520\n",
            "63/63 [==============================] - 27s 425ms/step - loss: 1.0402 - acc: 0.6218 - val_loss: 0.9831 - val_acc: 0.6575\n",
            "Epoch 7/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 1.0073 - acc: 0.6302\n",
            "Epoch 7: val_acc did not improve from 0.67520\n",
            "63/63 [==============================] - 27s 427ms/step - loss: 1.0073 - acc: 0.6302 - val_loss: 0.8770 - val_acc: 0.6713\n",
            "Epoch 8/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.9644 - acc: 0.6119\n",
            "Epoch 8: val_acc did not improve from 0.67520\n",
            "63/63 [==============================] - 27s 425ms/step - loss: 0.9644 - acc: 0.6119 - val_loss: 0.9028 - val_acc: 0.6476\n",
            "Epoch 9/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.8940 - acc: 0.6540\n",
            "Epoch 9: val_acc did not improve from 0.67520\n",
            "63/63 [==============================] - 27s 422ms/step - loss: 0.8940 - acc: 0.6540 - val_loss: 0.8957 - val_acc: 0.6673\n",
            "Epoch 10/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.9107 - acc: 0.6431\n",
            "Epoch 10: val_acc improved from 0.67520 to 0.71063, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 30s 483ms/step - loss: 0.9107 - acc: 0.6431 - val_loss: 0.8641 - val_acc: 0.7106\n",
            "Epoch 11/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.8603 - acc: 0.6678\n",
            "Epoch 11: val_acc did not improve from 0.71063\n",
            "63/63 [==============================] - 27s 425ms/step - loss: 0.8603 - acc: 0.6678 - val_loss: 0.9741 - val_acc: 0.6791\n",
            "Epoch 12/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.8828 - acc: 0.6495\n",
            "Epoch 12: val_acc improved from 0.71063 to 0.73228, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 29s 454ms/step - loss: 0.8828 - acc: 0.6495 - val_loss: 0.7683 - val_acc: 0.7323\n",
            "Epoch 13/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.8553 - acc: 0.6728\n",
            "Epoch 13: val_acc did not improve from 0.73228\n",
            "63/63 [==============================] - 27s 422ms/step - loss: 0.8553 - acc: 0.6728 - val_loss: 0.8553 - val_acc: 0.6870\n",
            "Epoch 14/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.8372 - acc: 0.6653\n",
            "Epoch 14: val_acc did not improve from 0.73228\n",
            "63/63 [==============================] - 27s 424ms/step - loss: 0.8372 - acc: 0.6653 - val_loss: 0.7550 - val_acc: 0.7323\n",
            "Epoch 15/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.8188 - acc: 0.6847\n",
            "Epoch 15: val_acc did not improve from 0.73228\n",
            "63/63 [==============================] - 27s 423ms/step - loss: 0.8188 - acc: 0.6847 - val_loss: 0.7556 - val_acc: 0.7224\n",
            "Epoch 16/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.8337 - acc: 0.6881\n",
            "Epoch 16: val_acc did not improve from 0.73228\n",
            "63/63 [==============================] - 27s 424ms/step - loss: 0.8337 - acc: 0.6881 - val_loss: 0.7859 - val_acc: 0.7008\n",
            "Epoch 17/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.7991 - acc: 0.6980\n",
            "Epoch 17: val_acc did not improve from 0.73228\n",
            "63/63 [==============================] - 27s 422ms/step - loss: 0.7991 - acc: 0.6980 - val_loss: 0.9386 - val_acc: 0.6614\n",
            "Epoch 18/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.8668 - acc: 0.6624\n",
            "Epoch 18: val_acc did not improve from 0.73228\n",
            "63/63 [==============================] - 27s 423ms/step - loss: 0.8668 - acc: 0.6624 - val_loss: 0.8157 - val_acc: 0.6850\n",
            "Epoch 19/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.7494 - acc: 0.7193\n",
            "Epoch 19: val_acc improved from 0.73228 to 0.74606, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 30s 475ms/step - loss: 0.7494 - acc: 0.7193 - val_loss: 0.7178 - val_acc: 0.7461\n",
            "Epoch 20/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.7792 - acc: 0.7015\n",
            "Epoch 20: val_acc improved from 0.74606 to 0.75197, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 451ms/step - loss: 0.7792 - acc: 0.7015 - val_loss: 0.7346 - val_acc: 0.7520\n",
            "Epoch 21/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.7200 - acc: 0.7287\n",
            "Epoch 21: val_acc did not improve from 0.75197\n",
            "63/63 [==============================] - 27s 421ms/step - loss: 0.7200 - acc: 0.7287 - val_loss: 0.8186 - val_acc: 0.7047\n",
            "Epoch 22/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.7616 - acc: 0.7045\n",
            "Epoch 22: val_acc did not improve from 0.75197\n",
            "63/63 [==============================] - 27s 419ms/step - loss: 0.7616 - acc: 0.7045 - val_loss: 0.7503 - val_acc: 0.7126\n",
            "Epoch 23/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.7070 - acc: 0.7238\n",
            "Epoch 23: val_acc improved from 0.75197 to 0.75591, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 446ms/step - loss: 0.7070 - acc: 0.7238 - val_loss: 0.6969 - val_acc: 0.7559\n",
            "Epoch 24/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6925 - acc: 0.7416\n",
            "Epoch 24: val_acc did not improve from 0.75591\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.6925 - acc: 0.7416 - val_loss: 0.7659 - val_acc: 0.7303\n",
            "Epoch 25/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6485 - acc: 0.7535\n",
            "Epoch 25: val_acc improved from 0.75591 to 0.75984, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 443ms/step - loss: 0.6485 - acc: 0.7535 - val_loss: 0.7193 - val_acc: 0.7598\n",
            "Epoch 26/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.7196 - acc: 0.7327\n",
            "Epoch 26: val_acc did not improve from 0.75984\n",
            "63/63 [==============================] - 26s 418ms/step - loss: 0.7196 - acc: 0.7327 - val_loss: 0.7029 - val_acc: 0.7382\n",
            "Epoch 27/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6786 - acc: 0.7431\n",
            "Epoch 27: val_acc did not improve from 0.75984\n",
            "63/63 [==============================] - 26s 419ms/step - loss: 0.6786 - acc: 0.7431 - val_loss: 0.6806 - val_acc: 0.7480\n",
            "Epoch 28/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6788 - acc: 0.7446\n",
            "Epoch 28: val_acc did not improve from 0.75984\n",
            "63/63 [==============================] - 26s 418ms/step - loss: 0.6788 - acc: 0.7446 - val_loss: 0.7698 - val_acc: 0.7303\n",
            "Epoch 29/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6102 - acc: 0.7609\n",
            "Epoch 29: val_acc improved from 0.75984 to 0.76772, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 447ms/step - loss: 0.6102 - acc: 0.7609 - val_loss: 0.6942 - val_acc: 0.7677\n",
            "Epoch 30/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6065 - acc: 0.7653\n",
            "Epoch 30: val_acc improved from 0.76772 to 0.76969, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 30s 474ms/step - loss: 0.6065 - acc: 0.7653 - val_loss: 0.6970 - val_acc: 0.7697\n",
            "Epoch 31/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5701 - acc: 0.7866\n",
            "Epoch 31: val_acc improved from 0.76969 to 0.77165, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 449ms/step - loss: 0.5701 - acc: 0.7866 - val_loss: 0.6845 - val_acc: 0.7717\n",
            "Epoch 32/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6394 - acc: 0.7644\n",
            "Epoch 32: val_acc did not improve from 0.77165\n",
            "63/63 [==============================] - 26s 420ms/step - loss: 0.6394 - acc: 0.7644 - val_loss: 0.6911 - val_acc: 0.7638\n",
            "Epoch 33/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5828 - acc: 0.7743\n",
            "Epoch 33: val_acc did not improve from 0.77165\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.5828 - acc: 0.7743 - val_loss: 0.7000 - val_acc: 0.7657\n",
            "Epoch 34/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6648 - acc: 0.7441\n",
            "Epoch 34: val_acc did not improve from 0.77165\n",
            "63/63 [==============================] - 26s 419ms/step - loss: 0.6648 - acc: 0.7441 - val_loss: 0.6750 - val_acc: 0.7657\n",
            "Epoch 35/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6437 - acc: 0.7698\n",
            "Epoch 35: val_acc improved from 0.77165 to 0.77953, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 449ms/step - loss: 0.6437 - acc: 0.7698 - val_loss: 0.6600 - val_acc: 0.7795\n",
            "Epoch 36/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5851 - acc: 0.7777\n",
            "Epoch 36: val_acc did not improve from 0.77953\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.5851 - acc: 0.7777 - val_loss: 0.6899 - val_acc: 0.7677\n",
            "Epoch 37/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.6138 - acc: 0.7698\n",
            "Epoch 37: val_acc improved from 0.77953 to 0.78543, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 445ms/step - loss: 0.6138 - acc: 0.7698 - val_loss: 0.6352 - val_acc: 0.7854\n",
            "Epoch 38/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5213 - acc: 0.8045\n",
            "Epoch 38: val_acc did not improve from 0.78543\n",
            "63/63 [==============================] - 27s 420ms/step - loss: 0.5213 - acc: 0.8045 - val_loss: 0.7079 - val_acc: 0.7618\n",
            "Epoch 39/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5097 - acc: 0.7995\n",
            "Epoch 39: val_acc did not improve from 0.78543\n",
            "63/63 [==============================] - 28s 443ms/step - loss: 0.5097 - acc: 0.7995 - val_loss: 0.7350 - val_acc: 0.7756\n",
            "Epoch 40/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5724 - acc: 0.7861\n",
            "Epoch 40: val_acc did not improve from 0.78543\n",
            "63/63 [==============================] - 26s 418ms/step - loss: 0.5724 - acc: 0.7861 - val_loss: 0.6310 - val_acc: 0.7736\n",
            "Epoch 41/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5441 - acc: 0.7950\n",
            "Epoch 41: val_acc did not improve from 0.78543\n",
            "63/63 [==============================] - 26s 418ms/step - loss: 0.5441 - acc: 0.7950 - val_loss: 0.7423 - val_acc: 0.7697\n",
            "Epoch 42/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5848 - acc: 0.7767\n",
            "Epoch 42: val_acc did not improve from 0.78543\n",
            "63/63 [==============================] - 26s 420ms/step - loss: 0.5848 - acc: 0.7767 - val_loss: 0.6689 - val_acc: 0.7736\n",
            "Epoch 43/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5477 - acc: 0.8054\n",
            "Epoch 43: val_acc did not improve from 0.78543\n",
            "63/63 [==============================] - 27s 421ms/step - loss: 0.5477 - acc: 0.8054 - val_loss: 0.6424 - val_acc: 0.7815\n",
            "Epoch 44/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5425 - acc: 0.8000\n",
            "Epoch 44: val_acc did not improve from 0.78543\n",
            "63/63 [==============================] - 27s 420ms/step - loss: 0.5425 - acc: 0.8000 - val_loss: 0.7245 - val_acc: 0.7539\n",
            "Epoch 45/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5726 - acc: 0.7832\n",
            "Epoch 45: val_acc did not improve from 0.78543\n",
            "63/63 [==============================] - 27s 422ms/step - loss: 0.5726 - acc: 0.7832 - val_loss: 0.6537 - val_acc: 0.7776\n",
            "Epoch 46/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5800 - acc: 0.7752\n",
            "Epoch 46: val_acc improved from 0.78543 to 0.79331, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 449ms/step - loss: 0.5800 - acc: 0.7752 - val_loss: 0.6237 - val_acc: 0.7933\n",
            "Epoch 47/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5071 - acc: 0.8069\n",
            "Epoch 47: val_acc did not improve from 0.79331\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.5071 - acc: 0.8069 - val_loss: 0.7499 - val_acc: 0.7638\n",
            "Epoch 48/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5866 - acc: 0.7802\n",
            "Epoch 48: val_acc improved from 0.79331 to 0.81102, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 448ms/step - loss: 0.5866 - acc: 0.7802 - val_loss: 0.6247 - val_acc: 0.8110\n",
            "Epoch 49/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5078 - acc: 0.8079\n",
            "Epoch 49: val_acc did not improve from 0.81102\n",
            "63/63 [==============================] - 27s 420ms/step - loss: 0.5078 - acc: 0.8079 - val_loss: 0.6277 - val_acc: 0.7953\n",
            "Epoch 50/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4935 - acc: 0.8178\n",
            "Epoch 50: val_acc did not improve from 0.81102\n",
            "63/63 [==============================] - 28s 447ms/step - loss: 0.4935 - acc: 0.8178 - val_loss: 0.7275 - val_acc: 0.7638\n",
            "Epoch 51/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5232 - acc: 0.7950\n",
            "Epoch 51: val_acc did not improve from 0.81102\n",
            "63/63 [==============================] - 26s 420ms/step - loss: 0.5232 - acc: 0.7950 - val_loss: 0.6082 - val_acc: 0.7953\n",
            "Epoch 52/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5313 - acc: 0.8054\n",
            "Epoch 52: val_acc improved from 0.81102 to 0.81299, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 449ms/step - loss: 0.5313 - acc: 0.8054 - val_loss: 0.6331 - val_acc: 0.8130\n",
            "Epoch 53/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4981 - acc: 0.8124\n",
            "Epoch 53: val_acc did not improve from 0.81299\n",
            "63/63 [==============================] - 27s 420ms/step - loss: 0.4981 - acc: 0.8124 - val_loss: 0.6244 - val_acc: 0.7992\n",
            "Epoch 54/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5610 - acc: 0.7827\n",
            "Epoch 54: val_acc did not improve from 0.81299\n",
            "63/63 [==============================] - 27s 419ms/step - loss: 0.5610 - acc: 0.7827 - val_loss: 0.6884 - val_acc: 0.7992\n",
            "Epoch 55/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5081 - acc: 0.8124\n",
            "Epoch 55: val_acc did not improve from 0.81299\n",
            "63/63 [==============================] - 27s 418ms/step - loss: 0.5081 - acc: 0.8124 - val_loss: 0.7174 - val_acc: 0.7736\n",
            "Epoch 56/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4764 - acc: 0.8178\n",
            "Epoch 56: val_acc improved from 0.81299 to 0.81890, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 447ms/step - loss: 0.4764 - acc: 0.8178 - val_loss: 0.6167 - val_acc: 0.8189\n",
            "Epoch 57/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4799 - acc: 0.8178\n",
            "Epoch 57: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.4799 - acc: 0.8178 - val_loss: 0.6081 - val_acc: 0.8031\n",
            "Epoch 58/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4937 - acc: 0.8144\n",
            "Epoch 58: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.4937 - acc: 0.8144 - val_loss: 0.6415 - val_acc: 0.7815\n",
            "Epoch 59/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5014 - acc: 0.8208\n",
            "Epoch 59: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.5014 - acc: 0.8208 - val_loss: 0.6703 - val_acc: 0.7953\n",
            "Epoch 60/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5132 - acc: 0.8153\n",
            "Epoch 60: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.5132 - acc: 0.8153 - val_loss: 0.7966 - val_acc: 0.7638\n",
            "Epoch 61/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5149 - acc: 0.8168\n",
            "Epoch 61: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 28s 437ms/step - loss: 0.5149 - acc: 0.8168 - val_loss: 0.7179 - val_acc: 0.7520\n",
            "Epoch 62/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5756 - acc: 0.7772\n",
            "Epoch 62: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.5756 - acc: 0.7772 - val_loss: 0.7488 - val_acc: 0.7815\n",
            "Epoch 63/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5530 - acc: 0.7926\n",
            "Epoch 63: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.5530 - acc: 0.7926 - val_loss: 0.7284 - val_acc: 0.7461\n",
            "Epoch 64/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5314 - acc: 0.8040\n",
            "Epoch 64: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.5314 - acc: 0.8040 - val_loss: 0.7040 - val_acc: 0.8071\n",
            "Epoch 65/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4836 - acc: 0.8312\n",
            "Epoch 65: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.4836 - acc: 0.8312 - val_loss: 0.6544 - val_acc: 0.8071\n",
            "Epoch 66/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4800 - acc: 0.8233\n",
            "Epoch 66: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.4800 - acc: 0.8233 - val_loss: 0.6687 - val_acc: 0.8130\n",
            "Epoch 67/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4831 - acc: 0.8228\n",
            "Epoch 67: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.4831 - acc: 0.8228 - val_loss: 0.6826 - val_acc: 0.8012\n",
            "Epoch 68/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4765 - acc: 0.8173\n",
            "Epoch 68: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 413ms/step - loss: 0.4765 - acc: 0.8173 - val_loss: 0.7385 - val_acc: 0.7972\n",
            "Epoch 69/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5108 - acc: 0.8094\n",
            "Epoch 69: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 418ms/step - loss: 0.5108 - acc: 0.8094 - val_loss: 0.9184 - val_acc: 0.7480\n",
            "Epoch 70/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5437 - acc: 0.7832\n",
            "Epoch 70: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 27s 421ms/step - loss: 0.5437 - acc: 0.7832 - val_loss: 0.7820 - val_acc: 0.7756\n",
            "Epoch 71/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4993 - acc: 0.8030\n",
            "Epoch 71: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.4993 - acc: 0.8030 - val_loss: 0.6979 - val_acc: 0.7953\n",
            "Epoch 72/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.5129 - acc: 0.8050\n",
            "Epoch 72: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.5129 - acc: 0.8050 - val_loss: 0.7558 - val_acc: 0.7992\n",
            "Epoch 73/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4837 - acc: 0.8193\n",
            "Epoch 73: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.4837 - acc: 0.8193 - val_loss: 0.7178 - val_acc: 0.7953\n",
            "Epoch 74/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4445 - acc: 0.8302\n",
            "Epoch 74: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.4445 - acc: 0.8302 - val_loss: 0.6570 - val_acc: 0.7874\n",
            "Epoch 75/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4693 - acc: 0.8262\n",
            "Epoch 75: val_acc did not improve from 0.81890\n",
            "63/63 [==============================] - 26s 419ms/step - loss: 0.4693 - acc: 0.8262 - val_loss: 0.7479 - val_acc: 0.7756\n",
            "Epoch 76/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4362 - acc: 0.8322\n",
            "Epoch 76: val_acc improved from 0.81890 to 0.82087, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 446ms/step - loss: 0.4362 - acc: 0.8322 - val_loss: 0.6259 - val_acc: 0.8209\n",
            "Epoch 77/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4408 - acc: 0.8411\n",
            "Epoch 77: val_acc did not improve from 0.82087\n",
            "63/63 [==============================] - 26s 413ms/step - loss: 0.4408 - acc: 0.8411 - val_loss: 0.7230 - val_acc: 0.7854\n",
            "Epoch 78/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4961 - acc: 0.8203\n",
            "Epoch 78: val_acc did not improve from 0.82087\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.4961 - acc: 0.8203 - val_loss: 0.8612 - val_acc: 0.7933\n",
            "Epoch 79/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4463 - acc: 0.8371\n",
            "Epoch 79: val_acc did not improve from 0.82087\n",
            "63/63 [==============================] - 26s 420ms/step - loss: 0.4463 - acc: 0.8371 - val_loss: 0.8192 - val_acc: 0.8130\n",
            "Epoch 80/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4286 - acc: 0.8327\n",
            "Epoch 80: val_acc did not improve from 0.82087\n",
            "63/63 [==============================] - 26s 418ms/step - loss: 0.4286 - acc: 0.8327 - val_loss: 0.6715 - val_acc: 0.8031\n",
            "Epoch 81/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4347 - acc: 0.8366\n",
            "Epoch 81: val_acc did not improve from 0.82087\n",
            "63/63 [==============================] - 28s 445ms/step - loss: 0.4347 - acc: 0.8366 - val_loss: 0.6738 - val_acc: 0.8051\n",
            "Epoch 82/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.3767 - acc: 0.8624\n",
            "Epoch 82: val_acc improved from 0.82087 to 0.83858, saving model to best_model_VGG16.h5\n",
            "63/63 [==============================] - 28s 449ms/step - loss: 0.3767 - acc: 0.8624 - val_loss: 0.6452 - val_acc: 0.8386\n",
            "Epoch 83/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4602 - acc: 0.8287\n",
            "Epoch 83: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 27s 418ms/step - loss: 0.4602 - acc: 0.8287 - val_loss: 0.7103 - val_acc: 0.7854\n",
            "Epoch 84/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4192 - acc: 0.8465\n",
            "Epoch 84: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 27s 421ms/step - loss: 0.4192 - acc: 0.8465 - val_loss: 0.6410 - val_acc: 0.8110\n",
            "Epoch 85/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4153 - acc: 0.8401\n",
            "Epoch 85: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 419ms/step - loss: 0.4153 - acc: 0.8401 - val_loss: 0.7176 - val_acc: 0.8051\n",
            "Epoch 86/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4354 - acc: 0.8401\n",
            "Epoch 86: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.4354 - acc: 0.8401 - val_loss: 0.6523 - val_acc: 0.7933\n",
            "Epoch 87/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4204 - acc: 0.8470\n",
            "Epoch 87: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.4204 - acc: 0.8470 - val_loss: 0.6934 - val_acc: 0.8130\n",
            "Epoch 88/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4087 - acc: 0.8470\n",
            "Epoch 88: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 413ms/step - loss: 0.4087 - acc: 0.8470 - val_loss: 0.6692 - val_acc: 0.8071\n",
            "Epoch 89/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4294 - acc: 0.8337\n",
            "Epoch 89: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.4294 - acc: 0.8337 - val_loss: 0.7076 - val_acc: 0.8130\n",
            "Epoch 90/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4090 - acc: 0.8455\n",
            "Epoch 90: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 413ms/step - loss: 0.4090 - acc: 0.8455 - val_loss: 0.6689 - val_acc: 0.8366\n",
            "Epoch 91/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4815 - acc: 0.8267\n",
            "Epoch 91: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.4815 - acc: 0.8267 - val_loss: 0.6685 - val_acc: 0.7972\n",
            "Epoch 92/100\n",
            "63/63 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8462\n",
            "Epoch 92: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 28s 438ms/step - loss: 0.4079 - acc: 0.8460 - val_loss: 0.6367 - val_acc: 0.8091\n",
            "Epoch 93/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4856 - acc: 0.8129\n",
            "Epoch 93: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.4856 - acc: 0.8129 - val_loss: 0.6272 - val_acc: 0.8051\n",
            "Epoch 94/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4440 - acc: 0.8401\n",
            "Epoch 94: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.4440 - acc: 0.8401 - val_loss: 0.8122 - val_acc: 0.8031\n",
            "Epoch 95/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4672 - acc: 0.8218\n",
            "Epoch 95: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.4672 - acc: 0.8218 - val_loss: 0.6555 - val_acc: 0.8071\n",
            "Epoch 96/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4316 - acc: 0.8480\n",
            "Epoch 96: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.4316 - acc: 0.8480 - val_loss: 0.6801 - val_acc: 0.8051\n",
            "Epoch 97/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4137 - acc: 0.8485\n",
            "Epoch 97: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.4137 - acc: 0.8485 - val_loss: 0.8088 - val_acc: 0.7913\n",
            "Epoch 98/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4126 - acc: 0.8594\n",
            "Epoch 98: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.4126 - acc: 0.8594 - val_loss: 0.7475 - val_acc: 0.7795\n",
            "Epoch 99/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4146 - acc: 0.8515\n",
            "Epoch 99: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.4146 - acc: 0.8515 - val_loss: 0.6953 - val_acc: 0.8091\n",
            "Epoch 100/100\n",
            "64/63 [==============================] - ETA: 0s - loss: 0.4303 - acc: 0.8475\n",
            "Epoch 100: val_acc did not improve from 0.83858\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.4303 - acc: 0.8475 - val_loss: 0.7318 - val_acc: 0.7992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "btIHp8HrB7mt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}